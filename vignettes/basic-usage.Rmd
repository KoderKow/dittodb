---
title: "Recording SQL queries with dbtest"
author: "Mauricio Vargas"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
bibliography: ../inst/REFERENCES.bib
vignette: >
  %\VignetteIndexEntry{Recording SQL queries with dbtest}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, cache = TRUE, echo = FALSE, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(eval = TRUE, message = FALSE, warning = FALSE)
```

# Scope

The present consists in mocking the connection to a real PostgreSQL server
that contains nycflights13 database version amongst other databases.

This example is for you if you ever wondered how to use scripts that you use
at the office when you are at home or travelling.

Many of use have to use databases that are only accesible from a local network. 
We provide `with_mock_db()` that wraps the code and makes it reproducible
outside the office.

# Exploring nycflights13

nycflights13 contains airline on-time data for all flights departing NYC in
2013.  Also includes useful 'metadata' on airlines, airports, weather, an
planes.
    
Have a look to the database schema:

![nycflights relational diagram.](relational-nycflights.svg)

# Recording queries

Suppose we are asked to analyze the flights to only show flights with planes that have flown at least 100 flights.

One would find all planes that have flown at least 100 flights. The only consideration would be to filter those flights with missing tail number or those will be treated as a single plane.

This is what I would do at the office:
```{r, error=TRUE}
library(dplyr)
library(dbplyr)

con_psql <- RPostgreSQL::dbConnect(
  drv = DBI::dbDriver("PostgreSQL"),
  dbname = "dbtest",
  host = "postgres.server",
  user = "dbtest",
  password = "_dbtest_"
)

tbl(con_psql, in_schema("public", "flights")) %>%
  filter(!is.na(tailnum)) %>%
  group_by(tailnum) %>%
  count() %>%
  filter(n >= 10L)
```

However, this won't work outside the workplace. Among other causes, postgres.server is an
alias to an IP only accesible from the local network.

*Important*: This was just an example. Please never write your passwords in scripts, use the Rprofile
instead.

From the office we can save the query and then mock the connection instead of saving the
results as CSV or TXT:
```{r, eval=FALSE}
start_capturing()

con_psql <- RPostgreSQL::dbConnect(
  drv = DBI::dbDriver("PostgreSQL"),
  dbname = "dbtest",
  host = "postgres.server",
  user = "dbtest",
  password = "_dbtest_"
)

tbl(con_psql, in_schema("public", "flights")) %>%
  filter(!is.na(tailnum)) %>%
  group_by(tailnum) %>%
  count() %>%
  filter(n >= 10L)

dbDisconnect(con_psql)

stop_capturing()
```

# Reproducing query results

If there was a success capturing one or more queries, then we are able to
replicate the result connected to a different network or even without internet
access:

```{r}
flights_100 <- with_mock_db({
  con_psql <- RPostgreSQL::dbConnect(
    drv = DBI::dbDriver("PostgreSQL"),
    dbname = "dbtest",
    host = "postgres.server",
    user = "dbtest",
    password = "_dbtest_"
  )
  
  tbl(con_psql, in_schema("public", "flights")) %>%
    filter(!is.na(tailnum)) %>%
    group_by(tailnum) %>%
    count() %>%
    filter(n >= 10L)
})

flights_100
```
